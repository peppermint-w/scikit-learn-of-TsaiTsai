{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、多项式朴素贝叶斯MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设概率分布是服从一个**简单多项式**分布。多项式分布来源于统计学中的多项式实验，这种实验可以具体解释为：实验包括n次重复试验，每项试验都有不同的可能结果。在任何给定的试验中，特定结果发生的概率是不变的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.多项式分布擅长的是**分类型变量**，在其原理假设中，$P(x_i|Y)$的概率是离散的，并且不同$x_i$下的$P(x_i|Y)$相互独立，互不影响。虽然sklearn中的多项式分布也可以处理连续型变量，但现实中，如果我们真的想要处理**连续型变量**，我们应当使用**高斯朴素贝叶斯**。<br>\n",
    "2.多项式实验中的实验结果都很具体，它所涉及的特征往往是**次数/频率/计数**出现与否这样的概念，这些概念都是离散的正整数，因此sklearn中的多项式朴素贝叶斯不接受**负值**的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于这样的特性，多项式朴素贝叶斯的特征矩阵经常是**稀疏矩阵**（不一定总是稀疏矩阵)，并且它经常被用于**文本分类**。可以使用著名的**TF-IDF**向量技术，也可以使用常见并且简单的**单词计数向量**手段与贝叶斯配合使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在$Y=c$这个分类下第$i$个特征所对应的参数$\\theta_{ci}$：\n",
    "$$\\theta_{ci}=\\frac{特征X_i在Y=c这个分类下的所有样本的取值总和}{所有特征在Y=c这个分类下的所有样本的取值总和}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.naive_bayes.MultinomialNB`(alpha=1.0, fit_prior=True, class_prior=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**alpha**：浮点数，可不填<br>\n",
    "拉普拉斯或利德斯通平滑的参数$\\alpha$，如果设置为0则表示完全没有平滑选项。但是需要注意的是，平滑相当于人为给概率加上一些噪音，因此$\\alpha$设置得越大，多项式朴素贝叶斯的精确性会越低（虽然影响不是非常大)，布里尔分数也会逐渐升高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit_prior**：布尔值，可不填<br>\n",
    "是否学习先验概率$P(Y=c)$。如果设置为false，则不适用先验概率，而使用统一先验概率，即认为每个标签类出现的概率是$\\frac{1}{n\\_classes}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**class_prior**：形似数组的结构，结构为(n_classes,)<br>\n",
    "类的先验概率$P(Y=c)$。如果没有给出具体的先验概率则自动根据数据来进行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.导入需要的模块和库**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler #归一化\n",
    "from sklearn.naive_bayes import MultinomialNB #多项式朴素贝叶斯\n",
    "from sklearn.model_selection import train_test_split #训练集测试集分裂\n",
    "from sklearn.datasets import make_blobs #自制数据\n",
    "from sklearn.metrics import brier_score_loss #布里尔分数\n",
    "from sklearn.preprocessing import KBinsDiscretizer #分箱（连续→分类）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.建立数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1 = 500\n",
    "class_2 = 500 #两个类别分别设定500个样本\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]] #设定两个类别的中心\n",
    "clusters_std = [0.5, 0.5] #设定两个类别的方差\n",
    "X, y = make_blobs(n_samples=[class_1, class_2],\n",
    "                  centers=centers,\n",
    "                  cluster_std=clusters_std,\n",
    "                  random_state=0,\n",
    "                  shuffle=False\n",
    "                  )\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,y,test_size=0.3,random_state=420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.归一化，确保输入的矩阵不带有负数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler().fit(Xtrain)\n",
    "Xtrain_ = mms.transform(Xtrain)\n",
    "Xtest_ = mms.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.建立多项式朴素贝叶斯分类器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#拟合多项式朴素贝叶斯\n",
    "mnb = MultinomialNB().fit(Xtrain_, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）属性class_log_prior_：根据数据获取的每个标签类的对数先验概率$log(P(Y))$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.69029411, -0.69600841])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_log_prior_ #非常接近，没有样本不均衡问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_log_prior_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49857142857142855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ytrain == 1).sum()/Ytrain.shape[0] #标签为1的样本比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50142857, 0.49857143])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以使用np.exp来查看真正的概率值\n",
    "np.exp(mnb.class_log_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）属性feature\\_log\\_prob\\_：返回一个固定标签类别下的每个特征的对数概率$log(P(X_i|y))$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76164788, -0.62903951],\n",
       "       [-0.72500918, -0.6622691 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.feature_log_prob_ #2个特征，标签2个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.feature_log_prob_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）属性class\\_count\\_：在fit时每个标签类别下包含的样本数。当fit接口中的sample_weight被设置时，该接口返回的值也会受到加权的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([351., 349.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.class_count_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.分类器效果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(Xtest_) #接口predict：返回标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49847128, 0.50152872],\n",
       "       [0.50065987, 0.49934013],\n",
       "       [0.50122363, 0.49877637],\n",
       "       [0.50183745, 0.49816255],\n",
       "       [0.50146433, 0.49853567],\n",
       "       [0.50153147, 0.49846853],\n",
       "       [0.50204549, 0.49795451],\n",
       "       [0.50033124, 0.49966876],\n",
       "       [0.50105254, 0.49894746],\n",
       "       [0.50182815, 0.49817185],\n",
       "       [0.50270707, 0.49729293],\n",
       "       [0.50133396, 0.49866604],\n",
       "       [0.49820896, 0.50179104],\n",
       "       [0.50342829, 0.49657171],\n",
       "       [0.50099022, 0.49900978],\n",
       "       [0.49974388, 0.50025612],\n",
       "       [0.50423879, 0.49576121],\n",
       "       [0.50449207, 0.49550793],\n",
       "       [0.49818224, 0.50181776],\n",
       "       [0.50245485, 0.49754515],\n",
       "       [0.50393627, 0.49606373],\n",
       "       [0.50193571, 0.49806429],\n",
       "       [0.49996152, 0.50003848],\n",
       "       [0.50460038, 0.49539962],\n",
       "       [0.50261175, 0.49738825],\n",
       "       [0.50140163, 0.49859837],\n",
       "       [0.50332522, 0.49667478],\n",
       "       [0.50122253, 0.49877747],\n",
       "       [0.50409939, 0.49590061],\n",
       "       [0.49998717, 0.50001283],\n",
       "       [0.50179417, 0.49820583],\n",
       "       [0.5000057 , 0.4999943 ],\n",
       "       [0.50190643, 0.49809357],\n",
       "       [0.50022071, 0.49977929],\n",
       "       [0.50097776, 0.49902224],\n",
       "       [0.50305244, 0.49694756],\n",
       "       [0.50109969, 0.49890031],\n",
       "       [0.50159754, 0.49840246],\n",
       "       [0.50166181, 0.49833819],\n",
       "       [0.5013594 , 0.4986406 ],\n",
       "       [0.50138322, 0.49861678],\n",
       "       [0.50174823, 0.49825177],\n",
       "       [0.50346533, 0.49653467],\n",
       "       [0.49918461, 0.50081539],\n",
       "       [0.50097953, 0.49902047],\n",
       "       [0.50178893, 0.49821107],\n",
       "       [0.49990491, 0.50009509],\n",
       "       [0.50202801, 0.49797199],\n",
       "       [0.50176739, 0.49823261],\n",
       "       [0.50254336, 0.49745664],\n",
       "       [0.50116963, 0.49883037],\n",
       "       [0.49920141, 0.50079859],\n",
       "       [0.49944211, 0.50055789],\n",
       "       [0.50031645, 0.49968355],\n",
       "       [0.50153599, 0.49846401],\n",
       "       [0.50352461, 0.49647539],\n",
       "       [0.50049178, 0.49950822],\n",
       "       [0.49983178, 0.50016822],\n",
       "       [0.50289574, 0.49710426],\n",
       "       [0.50193747, 0.49806253],\n",
       "       [0.49961192, 0.50038808],\n",
       "       [0.50198825, 0.49801175],\n",
       "       [0.50289658, 0.49710342],\n",
       "       [0.50218643, 0.49781357],\n",
       "       [0.49888163, 0.50111837],\n",
       "       [0.49920224, 0.50079776],\n",
       "       [0.50151585, 0.49848415],\n",
       "       [0.50230998, 0.49769002],\n",
       "       [0.50400072, 0.49599928],\n",
       "       [0.50138781, 0.49861219],\n",
       "       [0.50001327, 0.49998673],\n",
       "       [0.49982061, 0.50017939],\n",
       "       [0.50133343, 0.49866657],\n",
       "       [0.503153  , 0.496847  ],\n",
       "       [0.50180689, 0.49819311],\n",
       "       [0.50141445, 0.49858555],\n",
       "       [0.50248588, 0.49751412],\n",
       "       [0.50308391, 0.49691609],\n",
       "       [0.50024574, 0.49975426],\n",
       "       [0.50173534, 0.49826466],\n",
       "       [0.50018764, 0.49981236],\n",
       "       [0.50171743, 0.49828257],\n",
       "       [0.501695  , 0.498305  ],\n",
       "       [0.50357487, 0.49642513],\n",
       "       [0.50245246, 0.49754754],\n",
       "       [0.50233437, 0.49766563],\n",
       "       [0.50190721, 0.49809279],\n",
       "       [0.49839991, 0.50160009],\n",
       "       [0.50221084, 0.49778916],\n",
       "       [0.5012638 , 0.4987362 ],\n",
       "       [0.50199765, 0.49800235],\n",
       "       [0.50100067, 0.49899933],\n",
       "       [0.50122519, 0.49877481],\n",
       "       [0.50358523, 0.49641477],\n",
       "       [0.50353492, 0.49646508],\n",
       "       [0.50060048, 0.49939952],\n",
       "       [0.50261115, 0.49738885],\n",
       "       [0.50170128, 0.49829872],\n",
       "       [0.50084485, 0.49915515],\n",
       "       [0.49977894, 0.50022106],\n",
       "       [0.50134207, 0.49865793],\n",
       "       [0.49967049, 0.50032951],\n",
       "       [0.50394134, 0.49605866],\n",
       "       [0.50143828, 0.49856172],\n",
       "       [0.50356078, 0.49643922],\n",
       "       [0.50332876, 0.49667124],\n",
       "       [0.50095206, 0.49904794],\n",
       "       [0.50220001, 0.49779999],\n",
       "       [0.50256184, 0.49743816],\n",
       "       [0.50166902, 0.49833098],\n",
       "       [0.50254134, 0.49745866],\n",
       "       [0.5004789 , 0.4995211 ],\n",
       "       [0.50302788, 0.49697212],\n",
       "       [0.50052704, 0.49947296],\n",
       "       [0.50219724, 0.49780276],\n",
       "       [0.50026189, 0.49973811],\n",
       "       [0.50095584, 0.49904416],\n",
       "       [0.50206864, 0.49793136],\n",
       "       [0.50010878, 0.49989122],\n",
       "       [0.50109718, 0.49890282],\n",
       "       [0.50162885, 0.49837115],\n",
       "       [0.50020595, 0.49979405],\n",
       "       [0.50067955, 0.49932045],\n",
       "       [0.50280886, 0.49719114],\n",
       "       [0.50237353, 0.49762647],\n",
       "       [0.50222485, 0.49777515],\n",
       "       [0.5001119 , 0.4998881 ],\n",
       "       [0.50112275, 0.49887725],\n",
       "       [0.50362029, 0.49637971],\n",
       "       [0.50054287, 0.49945713],\n",
       "       [0.50070066, 0.49929934],\n",
       "       [0.50174149, 0.49825851],\n",
       "       [0.50190098, 0.49809902],\n",
       "       [0.5007135 , 0.4992865 ],\n",
       "       [0.50207309, 0.49792691],\n",
       "       [0.50270744, 0.49729256],\n",
       "       [0.50050176, 0.49949824],\n",
       "       [0.50142338, 0.49857662],\n",
       "       [0.50099023, 0.49900977],\n",
       "       [0.50084396, 0.49915604],\n",
       "       [0.50368091, 0.49631909],\n",
       "       [0.50272862, 0.49727138],\n",
       "       [0.50132287, 0.49867713],\n",
       "       [0.50401085, 0.49598915],\n",
       "       [0.50227543, 0.49772457],\n",
       "       [0.50117773, 0.49882227],\n",
       "       [0.50165111, 0.49834889],\n",
       "       [0.49957088, 0.50042912],\n",
       "       [0.50317179, 0.49682821],\n",
       "       [0.50098188, 0.49901812],\n",
       "       [0.5023283 , 0.4976717 ],\n",
       "       [0.50104249, 0.49895751],\n",
       "       [0.50104179, 0.49895821],\n",
       "       [0.501309  , 0.498691  ],\n",
       "       [0.50216322, 0.49783678],\n",
       "       [0.50110205, 0.49889795],\n",
       "       [0.50257045, 0.49742955],\n",
       "       [0.5013388 , 0.4986612 ],\n",
       "       [0.50053838, 0.49946162],\n",
       "       [0.50120029, 0.49879971],\n",
       "       [0.50127632, 0.49872368],\n",
       "       [0.50183619, 0.49816381],\n",
       "       [0.50009396, 0.49990604],\n",
       "       [0.50128105, 0.49871895],\n",
       "       [0.50158456, 0.49841544],\n",
       "       [0.50190347, 0.49809653],\n",
       "       [0.50228193, 0.49771807],\n",
       "       [0.50242186, 0.49757814],\n",
       "       [0.50201385, 0.49798615],\n",
       "       [0.50201075, 0.49798925],\n",
       "       [0.5007775 , 0.4992225 ],\n",
       "       [0.50240731, 0.49759269],\n",
       "       [0.49865226, 0.50134774],\n",
       "       [0.50451121, 0.49548879],\n",
       "       [0.50254794, 0.49745206],\n",
       "       [0.5039106 , 0.4960894 ],\n",
       "       [0.50200714, 0.49799286],\n",
       "       [0.50227154, 0.49772846],\n",
       "       [0.50115683, 0.49884317],\n",
       "       [0.50254911, 0.49745089],\n",
       "       [0.50062667, 0.49937333],\n",
       "       [0.50324846, 0.49675154],\n",
       "       [0.50165038, 0.49834962],\n",
       "       [0.50200129, 0.49799871],\n",
       "       [0.50034533, 0.49965467],\n",
       "       [0.50051902, 0.49948098],\n",
       "       [0.50029115, 0.49970885],\n",
       "       [0.50209651, 0.49790349],\n",
       "       [0.50240236, 0.49759764],\n",
       "       [0.50092696, 0.49907304],\n",
       "       [0.50250997, 0.49749003],\n",
       "       [0.4985069 , 0.5014931 ],\n",
       "       [0.4994373 , 0.5005627 ],\n",
       "       [0.5024844 , 0.4975156 ],\n",
       "       [0.50120384, 0.49879616],\n",
       "       [0.49970062, 0.50029938],\n",
       "       [0.50154039, 0.49845961],\n",
       "       [0.50257601, 0.49742399],\n",
       "       [0.5015003 , 0.4984997 ],\n",
       "       [0.50034533, 0.49965467],\n",
       "       [0.5020367 , 0.4979633 ],\n",
       "       [0.5022038 , 0.4977962 ],\n",
       "       [0.50057621, 0.49942379],\n",
       "       [0.50128065, 0.49871935],\n",
       "       [0.50042842, 0.49957158],\n",
       "       [0.50330239, 0.49669761],\n",
       "       [0.50128544, 0.49871456],\n",
       "       [0.50196417, 0.49803583],\n",
       "       [0.50194098, 0.49805902],\n",
       "       [0.50115364, 0.49884636],\n",
       "       [0.50299407, 0.49700593],\n",
       "       [0.50130317, 0.49869683],\n",
       "       [0.50375311, 0.49624689],\n",
       "       [0.50121088, 0.49878912],\n",
       "       [0.50232441, 0.49767559],\n",
       "       [0.50272548, 0.49727452],\n",
       "       [0.50001357, 0.49998643],\n",
       "       [0.50093936, 0.49906064],\n",
       "       [0.50208529, 0.49791471],\n",
       "       [0.50137482, 0.49862518],\n",
       "       [0.50080493, 0.49919507],\n",
       "       [0.50332574, 0.49667426],\n",
       "       [0.50302616, 0.49697384],\n",
       "       [0.50196237, 0.49803763],\n",
       "       [0.5023057 , 0.4976943 ],\n",
       "       [0.5006412 , 0.4993588 ],\n",
       "       [0.50224065, 0.49775935],\n",
       "       [0.5010883 , 0.4989117 ],\n",
       "       [0.50133566, 0.49866434],\n",
       "       [0.50233576, 0.49766424],\n",
       "       [0.50184149, 0.49815851],\n",
       "       [0.50098641, 0.49901359],\n",
       "       [0.5019006 , 0.4980994 ],\n",
       "       [0.50107183, 0.49892817],\n",
       "       [0.50143271, 0.49856729],\n",
       "       [0.50203595, 0.49796405],\n",
       "       [0.5026515 , 0.4973485 ],\n",
       "       [0.50377703, 0.49622297],\n",
       "       [0.49893439, 0.50106561],\n",
       "       [0.50339275, 0.49660725],\n",
       "       [0.50152766, 0.49847234],\n",
       "       [0.50158634, 0.49841366],\n",
       "       [0.50000096, 0.49999904],\n",
       "       [0.50045491, 0.49954509],\n",
       "       [0.50208306, 0.49791694],\n",
       "       [0.50352855, 0.49647145],\n",
       "       [0.50237312, 0.49762688],\n",
       "       [0.49928464, 0.50071536],\n",
       "       [0.50297955, 0.49702045],\n",
       "       [0.50170373, 0.49829627],\n",
       "       [0.50143102, 0.49856898],\n",
       "       [0.50330941, 0.49669059],\n",
       "       [0.50211473, 0.49788527],\n",
       "       [0.50202076, 0.49797924],\n",
       "       [0.50051225, 0.49948775],\n",
       "       [0.50112964, 0.49887036],\n",
       "       [0.50185392, 0.49814608],\n",
       "       [0.49966058, 0.50033942],\n",
       "       [0.50075293, 0.49924707],\n",
       "       [0.50071296, 0.49928704],\n",
       "       [0.49923395, 0.50076605],\n",
       "       [0.50080148, 0.49919852],\n",
       "       [0.49827919, 0.50172081],\n",
       "       [0.50168248, 0.49831752],\n",
       "       [0.49995601, 0.50004399],\n",
       "       [0.5014818 , 0.4985182 ],\n",
       "       [0.5008324 , 0.4991676 ],\n",
       "       [0.50225201, 0.49774799],\n",
       "       [0.50041346, 0.49958654],\n",
       "       [0.50008176, 0.49991824],\n",
       "       [0.50275251, 0.49724749],\n",
       "       [0.5013088 , 0.4986912 ],\n",
       "       [0.50199637, 0.49800363],\n",
       "       [0.50250964, 0.49749036],\n",
       "       [0.50279177, 0.49720823],\n",
       "       [0.50085703, 0.49914297],\n",
       "       [0.50363226, 0.49636774],\n",
       "       [0.50075518, 0.49924482],\n",
       "       [0.50160237, 0.49839763],\n",
       "       [0.50200633, 0.49799367],\n",
       "       [0.50294549, 0.49705451],\n",
       "       [0.50134492, 0.49865508],\n",
       "       [0.50113355, 0.49886645],\n",
       "       [0.5011625 , 0.4988375 ],\n",
       "       [0.50086075, 0.49913925],\n",
       "       [0.50223575, 0.49776425],\n",
       "       [0.50032738, 0.49967262],\n",
       "       [0.50110359, 0.49889641],\n",
       "       [0.50256978, 0.49743022],\n",
       "       [0.49850301, 0.50149699],\n",
       "       [0.5031758 , 0.4968242 ],\n",
       "       [0.50058575, 0.49941425],\n",
       "       [0.5004442 , 0.4995558 ],\n",
       "       [0.50093672, 0.49906328],\n",
       "       [0.50332508, 0.49667492],\n",
       "       [0.50399354, 0.49600646],\n",
       "       [0.50351518, 0.49648482],\n",
       "       [0.50156107, 0.49843893],\n",
       "       [0.50078711, 0.49921289],\n",
       "       [0.50197128, 0.49802872]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(Xtest_) #接口predict_proba：每个样本在每个标签取值下的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5433333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(Xtest_,Ytest) #接口score：准确度（不高）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24977828412546027"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#布里尔分数：较高\n",
    "brier_score_loss(Ytest,mnb.predict_proba(Xtest_)[:,1],pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.效果不太理想，思考一下多项式贝叶斯的性质，应该做点什么？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把Xtiain转换成分类型数据\n",
    "#注意Xtrain没有经过归一化，因为做哑变量之后自然所有的数据就不会有负数了\n",
    "kbs = KBinsDiscretizer(n_bins=10, encode='onehot').fit(Xtrain) #独热，分10箱\n",
    "Xtrain_ = kbs.transform(Xtrain)\n",
    "Xtest_ = kbs.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_.shape #2个特征每个特征分了10个箱得到哑变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB().fit(Xtrain_, Ytrain)\n",
    "mnb.score(Xtest_,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014593932778211862"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,mnb.predict_proba(Xtest_)[:,1],pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，同样的数据，如果采用**哑变量**方式的**分箱**处理，多项式贝叶斯的效果会突飞猛进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、伯努利朴素贝叶斯BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项式朴素贝叶斯可同时处理**二项分布**(抛硬币）和**多项分布**(掷骰子)，其中二项分布又叫做伯努利分布，它是一种现实中常见并且拥有很多优越数学性质的分布。因此，既然有着多项式朴素贝叶斯，我们自然也就又专门用来处理**二项分布**的朴素贝叶斯：伯努利朴素贝叶斯。<br>\n",
    "伯努利贝叶斯类BernoulliN假设数据服从**多元伯努利分布**，并在此基础上应用朴素贝叶斯的训练和分类过程。多元伯努利分布简单来说，就是数据集中可以存在多个特征，但**每个特征都是二分类**的，可以以布尔变量表示，也可以表示为{0，1}或者{-1，1}等任意二分类组合。因此，这个类要求将样本转换为**二分类特征向量**，如果数据本身不是二分类的，那可以使用类中专门用来**二值化**的参数binarize来改变数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伯努利朴素贝叶斯与多项式朴素贝叶斯非常相似，都常用于处理**文本分类**数据。但由于伯努利朴素贝叶斯是处理二项分布，所以它更加在意的是“**存在与否**”，而不是“**出现多少次**”这样的次数或频率，这是伯努利贝叶斯与多项式贝叶斯的根本性不同。在文本分类的情况下，伯努利朴素贝叶斯可以使用**单词出现向量**（而不是单词计数向量）来训练分类器。**文档较短**的数据集上，伯努利朴素贝叶斯的效果会更加好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.naive_bayes.BernoulliNB`(alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**alpha**：浮点数，可不填<br>\n",
    "拉普拉斯或利德斯通平滑的参数$\\alpha$，如果设置为0则表示完全没有平滑选项。但是需要注意的是，平滑相当于人为给概率加上一些噪音，因此$\\alpha$设置得越大，多项式朴素贝叶斯的精确性会越低（虽然影响不是非常大)，布里尔分数也会逐渐升高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**binarize**：浮点数或None，可不填<br>\n",
    "将特征二值化的阈值，如果设定为None，则会假定特征已经被二值化完毕。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit_prior**：布尔值，可不填<br>\n",
    "是否学习先验概率$P(Y=c)$。如果设置为false，则不适用先验概率，而使用统一先验概率，即认为每个标签类出现的概率是$\\frac{1}{n\\_classes}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**class_prior**：形似数组的结构，结构为(n_classes,)<br>\n",
    "类的先验概率$P(Y=c)$。如果没有给出具体的先验概率则自动根据数据来进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说应该使用二值化的类`sklearn.preprocessing.Binarizer`来将特征一个个二值化，然而这样效率过低，因此选择**归一化**（不能输入负数）之后直接设置一个**阈值**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler().fit(Xtrain)\n",
    "Xtrain_ = mms.transform(Xtrain)\n",
    "Xtest_ = mms.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）不设置二值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49666666666666665"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnl_ = BernoulliNB().fit(Xtrain_, Ytrain) #实例化+拟合\n",
    "bnl_.score(Xtest_,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25000009482193225"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,bnl_.predict_proba(Xtest_)[:,1],pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）设置二值化阈值为0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnl = BernoulliNB(binarize=0.5).fit(Xtrain_, Ytrain) #二值化阈值0.5\n",
    "bnl.score(Xtest_,Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010405875827339534"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brier_score_loss(Ytest,bnl.predict_proba(Xtest_)[:,1],pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和多项式贝叶斯一样，伯努利贝叶斯的结果也受到数据结构非常大的影响。因此，根据数据的模样选择贝叶斯，是贝叶斯模型选择中十分重要的一点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、探索贝叶斯：贝叶斯的样本不均衡问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "探讨一个分类算法永远都逃不过的核心问题：**样本不平衡**。贝叶斯由于分类效力不算太好，因此对样本不平衡极为敏感，接下来就来看一看样本不平衡如何影响了贝叶斯。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.导入需要的模块，建立样本不平衡的数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB #多项式、高斯、伯努利\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs #自制数据集\n",
    "from sklearn.preprocessing import KBinsDiscretizer #分箱\n",
    "from sklearn.metrics import brier_score_loss as BS,recall_score,roc_auc_score as AUC #布里尔分数、recall（自创二分类数据）、AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1 = 50000 #多数类为50000个样本\n",
    "class_2 = 500 #少数类为500个样本\n",
    "centers = [[0.0, 0.0], [5.0, 5.0]] #设定两个类别的中心\n",
    "clusters_std = [3, 1] #设定两个类别的方差\n",
    "X, y = make_blobs(n_samples=[class_1, class_2],\n",
    "                  centers=centers,\n",
    "                  cluster_std=clusters_std,\n",
    "                  random_state=0,\n",
    "                  shuffle=False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50500, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.查看所有贝叶斯在样本不平衡数据集上的表现**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial\n",
      "\tBrier:0.007\n",
      "\tAccuracy:0.990\n",
      "\tRecall:0.000\n",
      "\tAUC:0.991\n",
      "Gaussian\n",
      "\tBrier:0.006\n",
      "\tAccuracy:0.990\n",
      "\tRecall:0.438\n",
      "\tAUC:0.993\n",
      "Bernoulli\n",
      "\tBrier:0.009\n",
      "\tAccuracy:0.987\n",
      "\tRecall:0.771\n",
      "\tAUC:0.987\n"
     ]
    }
   ],
   "source": [
    "name = [\"Multinomial\",\"Gaussian\",\"Bernoulli\"]\n",
    "models = [MultinomialNB(),GaussianNB(),BernoulliNB()]\n",
    "for name,clf in zip(name,models):\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,y,test_size=0.3,random_state=420)\n",
    "    \n",
    "    #除了高斯朴素贝叶斯之外需要分箱。2个特征分10箱→20个特征\n",
    "    if name != \"Gaussian\":\n",
    "        kbs = KBinsDiscretizer(n_bins=10, encode='onehot').fit(Xtrain)\n",
    "        Xtrain = kbs.transform(Xtrain)\n",
    "        Xtest = kbs.transform(Xtest)\n",
    "    \n",
    "    clf.fit(Xtrain,Ytrain) #拟合\n",
    "    y_pred = clf.predict(Xtest) #预测的分类结果\n",
    "    proba = clf.predict_proba(Xtest)[:,1] #每个样本在每个特征上的概率\n",
    "    score = clf.score(Xtest,Ytest) #准确率\n",
    "    print(name)\n",
    "    print(\"\\tBrier:{:.3f}\".format(BS(Ytest,proba,pos_label=1))) #布里尔分数\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score)) #准确度\n",
    "    print(\"\\tRecall:{:.3f}\".format(recall_score(Ytest,y_pred))) #召回率\n",
    "    print(\"\\tAUC:{:.3f}\".format(AUC(Ytest,proba))) #AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果上来看，**多项式朴素贝叶斯**判断出了所有的多数类样本，但放弃了全部的少数类样本，受到样本不均衡问题影响最严重。**高斯**比多项式在少数类的判断上更加成功一些，至少得到了43.8%的recall。**伯努利贝叶斯**虽然整体的准确度和布里尔分数不如多项式和高斯朴素贝叶斯和，但至少成功捕捉出了77.1%的少数类。可见，**伯努利贝叶斯最能够忍受样本不均衡问题**。<br>\n",
    "可是，伯努利贝叶斯只能用于处理**二项分布**数据，在现实中，强行将所有的数据都二值化不会永远得到好结果，在有多个特征的时候，更需要一个个去判断究竟二值化的**阈值**该取多少才能够让算法的效果优秀。这样做无疑是非常低效的。<br>\n",
    "那如果目标是捕捉少数类，应该怎么办呢？高斯朴素贝叶斯的效果虽然比多项式好，但是也没有好到可以用来帮助我们捕捉少数类的程度——43.8%，还不如抛硬币的结果。因此，孜孜不倦的统计学家们改进了朴素贝叶斯算法，修正了包括**无法处理样本不平衡**在内的传统朴素贝叶斯的众多缺点，得到了新兴贝叶斯算法：**补集朴素贝叶斯**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、改进多项式朴素贝叶斯：补集朴素贝叶斯ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "补集朴素贝叶斯（complement naive Bayes，CNB）算法是标准多项式朴素贝叶斯算法的改进。CNB的发明小组创造出CNB的初衷是为了解决贝叶斯中的“**朴素**”假设带来的各种问题，他们希望能够创造出数学方法以逃避朴素贝叶斯中的朴素假设，让算法能够不去关心所有特征之间是否是条件独立的。以此为基础，他们创造出了能够**解决样本不平衡**问题，并且能够一定程度上**忽略朴素假设**的补集朴素贝叶斯。在实验中，CNB的参数估计已经被证明比普通多项式朴素贝叶斯更稳定，并且它特别适合于样本不平衡的数据集。有时候，CNB在**文本分类**任务上的表现有时能够优于多项式朴素贝叶斯，因此现在补集朴素贝叶斯也开始逐渐流行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNB使用来自每个标签类别的**补集**的概率，并以此来计算每个特征的权重。$$\\theta_{i,j≠c}=\\frac{\\alpha_i+\\sum_{y_i≠c}x_{ij}}{\\alpha_in+\\sum_{i,y≠c}\\sum_{i=1}^{n}x_{ij}}$$其中$j$表示每个样本，$x_{ij}$表示在样本$j$上对于特征$i$下的取值，在文本分类中通常是计数的值或TF-IDF值，$\\alpha$是像标准多项式朴素贝叶斯中一样的平滑系数。其实就是多项式分布的逆向思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.naive_bayes.ComplementNB`(alpha=1.0, fit_prior=True, class_prior=None, norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**alpha**：浮点数，可不填<br>\n",
    "拉普拉斯或利德斯通平滑的参数α，如果设置为0则表示完全没有平滑选项。但是需要注意的是，平滑相当于人为给概率加上一些噪音，因此α设置得越大，多项式朴素贝叶斯的精确性会越低（虽然影响不是非常大)，布里尔分数也会逐渐升高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**norm**：布尔值，可不填<br>\n",
    "在计算权重的时候是否使用L2范式来规范权重的大小。默认不进行规范，即不跟从补集朴素贝叶斯算法的全部内容，如果希望进行规范，则设置True。TF-IDF通常默认为flase。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit_prior**：布尔值，可不填<br>\n",
    "是否学习先验概率$P(Y=c)$。如果设置为false，则不适用先验概率，而使用统一先验概率，即认为每个标签类出现的概率是$\\frac{1}{n\\_classes}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**class_prior**：形似数组的结构，结构为(n_classes,)<br>\n",
    "类的先验概率$P(Y=c)$。如果没有给出具体的先验概率则自动根据数据来进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial\n",
      "\tBrier:0.007\n",
      "\tAccuracy:0.990\n",
      "\tRecall:0.000\n",
      "\tAUC:0.991\n",
      "00:00:040924\n",
      "Gaussian\n",
      "\tBrier:0.006\n",
      "\tAccuracy:0.990\n",
      "\tRecall:0.438\n",
      "\tAUC:0.993\n",
      "00:00:020947\n",
      "Bernoulli\n",
      "\tBrier:0.009\n",
      "\tAccuracy:0.987\n",
      "\tRecall:0.771\n",
      "\tAUC:0.987\n",
      "00:00:034872\n",
      "Complement\n",
      "\tBrier:0.038\n",
      "\tAccuracy:0.953\n",
      "\tRecall:0.987\n",
      "\tAUC:0.991\n",
      "00:00:036900\n"
     ]
    }
   ],
   "source": [
    "name = [\"Multinomial\",\"Gaussian\",\"Bernoulli\",\"Complement\"]\n",
    "models = [MultinomialNB(),GaussianNB(),BernoulliNB(),ComplementNB()]\n",
    "for name,clf in zip(name,models):\n",
    "    times = time()\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,y,test_size=0.3,random_state=420)\n",
    "    #预处理\n",
    "    if name != \"Gaussian\":\n",
    "        kbs = KBinsDiscretizer(n_bins=10, encode='onehot').fit(Xtrain)\n",
    "        Xtrain = kbs.transform(Xtrain)\n",
    "        Xtest = kbs.transform(Xtest)\n",
    "    \n",
    "    clf.fit(Xtrain,Ytrain)\n",
    "    y_pred = clf.predict(Xtest)\n",
    "    proba = clf.predict_proba(Xtest)[:,1]\n",
    "    score = clf.score(Xtest,Ytest)\n",
    "    print(name)\n",
    "    print(\"\\tBrier:{:.3f}\".format(BS(Ytest,proba,pos_label=1)))\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "    print(\"\\tRecall:{:.3f}\".format(recall_score(Ytest,y_pred)))\n",
    "    print(\"\\tAUC:{:.3f}\".format(AUC(Ytest,proba)))\n",
    "    print(datetime.datetime.fromtimestamp(time()-times).strftime(\"%M:%S:%f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，补集朴素贝叶斯牺牲了部分整体的**精确度**和**布里尔分数**，但是得到了十分高的**召回率**Recall，捕捉出了98.7%的少数类，并且在此基础上维持了和原本的多项式朴素贝叶斯一致的AUC分数。和其他的贝叶斯算法比起来，我们的补集朴素贝叶斯的运行速度也十分优秀。如果目标是**捕捉少数类**，则选择**补集朴素贝叶斯**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
