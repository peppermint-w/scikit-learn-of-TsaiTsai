{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups #20类新闻文本\n",
    "from sklearn.feature_extraction.text import CountVectorizer #单词计数向量\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF #TF-IDF\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import brier_score_loss as BS #布里尔分数\n",
    "from sklearn.calibration import CalibratedClassifierCV #校准可靠性曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （一）文本编码技术简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.单词计数向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在开始分类之前，必须先将文本编码成数字。一种常用的方法是**单词计数向量**。在这种技术中，一个样本可以包含一段话或一篇文章，这个样本中如果出现了10个单词，就会有10个特征(n=10)，**每个特征代表一个单词**，**特征的取值表示这个单词在这个样本中总共出现了几次**，是一个**离散**的、代表**次数**的正整数。在sklearn当中，单词计数向量计数可以通过`feature_extraction.text.CountVectorizer`类实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [\"Machine learning is fascinating, it is wonderful\" #6个单词（重复的算1个）\n",
    "         ,\"Machine learning is a sensational techonology\" #2个单词（a不算？）\n",
    "         ,\"Elsa is a popular character\"] #3个单词\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(sample)\n",
    "X #3行（3句话即3个样本）11列（11个单词即11个特征）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['character',\n",
       " 'elsa',\n",
       " 'fascinating',\n",
       " 'is',\n",
       " 'it',\n",
       " 'learning',\n",
       " 'machine',\n",
       " 'popular',\n",
       " 'sensational',\n",
       " 'techonology',\n",
       " 'wonderful']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用接口get_feature_names()调用每个列的名称\n",
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>elsa</th>\n",
       "      <th>fascinating</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>popular</th>\n",
       "      <th>sensational</th>\n",
       "      <th>techonology</th>\n",
       "      <th>wonderful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character  elsa  fascinating  is  it  learning  machine  popular  \\\n",
       "0          0     0            1   2   1         1        1        0   \n",
       "1          0     0            0   1   0         1        1        0   \n",
       "2          1     1            0   1   0         0        0        1   \n",
       "\n",
       "   sensational  techonology  wonderful  \n",
       "0            0            0          1  \n",
       "1            1            1          0  \n",
       "2            0            0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#注意稀疏矩阵是无法输入pandas的，需要用toarray()\n",
    "CVresult = pd.DataFrame(X.toarray(),columns = vec.get_feature_names())\n",
    "CVresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这个编码结果可以发现两个问题：<br>\n",
    "1.补集朴素贝叶斯让**每个特征的权重除以自己的L2范式**，避免句子特别长的样本（在很多特征下都有值的样本）对$θ_{ci}$的贡献比其他样本更大；<br>\n",
    "2.通常'is'对语义没什么影响，但出现次数多，会占有较高的权重，对分类来说，这明显是对算法的一种误导。为了解决这个问题，可以使用单词在句子中所占的比例来编码单词，即**TF-IDF方法**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF全称term frequency-inverse document frequency，词频逆文档频率，是通过**单词在文档中出现的频率**来衡量其权重，也就是说，IDF的大小与一个词的常见程度成反比，这个词越常见，编码后为它设置的权重会倾向于越小，以此来压制频繁出现的一些无意义的词。在sklearn当中，使用`feature_extraction.text.TfidfVvectorizer`执行这种编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TF_i=\\frac{某个词i在文章中的出现次数}{文章的总词数}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$IDF=|log(\\frac{语料库的文档总数}{包含词条i的文档数+1})|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TF-IDF=TF_i*IDF$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x11 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TFIDF()\n",
    "X = vec.fit_transform(sample)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>elsa</th>\n",
       "      <th>fascinating</th>\n",
       "      <th>is</th>\n",
       "      <th>it</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>popular</th>\n",
       "      <th>sensational</th>\n",
       "      <th>techonology</th>\n",
       "      <th>wonderful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.501310</td>\n",
       "      <td>0.424396</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.322764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.406192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534093</td>\n",
       "      <td>0.534093</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   character      elsa  fascinating        is        it  learning   machine  \\\n",
       "0   0.000000  0.000000     0.424396  0.501310  0.424396  0.322764  0.322764   \n",
       "1   0.000000  0.000000     0.000000  0.315444  0.000000  0.406192  0.406192   \n",
       "2   0.546454  0.546454     0.000000  0.322745  0.000000  0.000000  0.000000   \n",
       "\n",
       "    popular  sensational  techonology  wonderful  \n",
       "0  0.000000     0.000000     0.000000   0.424396  \n",
       "1  0.000000     0.534093     0.534093   0.000000  \n",
       "2  0.546454     0.000000     0.000000   0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用接口get_feature_names()调用每个列的名称\n",
    "TFIDFresult = pd.DataFrame(X.toarray(),columns=vec.get_feature_names())\n",
    "TFIDFresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用TF-IDF编码之后，出现得多的单词的权重（theta）被降低了么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character      0.0625\n",
       "elsa           0.0625\n",
       "fascinating    0.0625\n",
       "is             0.2500\n",
       "it             0.0625\n",
       "learning       0.1250\n",
       "machine        0.1250\n",
       "popular        0.0625\n",
       "sensational    0.0625\n",
       "techonology    0.0625\n",
       "wonderful      0.0625\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CVresult.sum(axis=0)/CVresult.sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character      0.083071\n",
       "elsa           0.083071\n",
       "fascinating    0.064516\n",
       "is             0.173225\n",
       "it             0.064516\n",
       "learning       0.110815\n",
       "machine        0.110815\n",
       "popular        0.083071\n",
       "sensational    0.081192\n",
       "techonology    0.081192\n",
       "wonderful      0.064516\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFIDFresult.sum(axis=0)/TFIDFresult.sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将原本出现次数比较多的词压缩权重；将原本出现次数比较少的词增加权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （二）探索文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_20newsgroups()\n",
    "data.target_names #不同类型的新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"sci.space\" #科学技术 - 太空\n",
    "             ,\"rec.sport.hockey\" #运动 - 曲棍球\n",
    "             ,\"talk.politics.guns\" #政治 - 枪支问题\n",
    "             ,\"talk.politics.mideast\"] #政治 - 中东问题\n",
    "train = fetch_20newsgroups(subset=\"train\",categories = categories) #训练集\n",
    "test = fetch_20newsgroups(subset=\"test\",categories = categories) #测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec.sport.hockey',\n",
       " 'sci.space',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target_names #标签的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: tvartiai@vipunen.hut.fi (Tommi Vartiainen)\n",
      "Subject: Re: Finland/Sweden vs.NHL teams (WAS:Helsinki/Stockholm & NHL expansion)\n",
      "Nntp-Posting-Host: vipunen.hut.fi\n",
      "Organization: Helsinki University of Technology, Finland\n",
      "Lines: 51\n",
      "\n",
      "In <1993Apr16.195754.5476@ousrvr.oulu.fi> mep@phoenix.oulu.fi (Marko Poutiainen) writes:\n",
      "\n",
      ">: FINLAND:  \n",
      ">: \n",
      ">: D-Jyrki Lumme.......20\n",
      ">: D-Teppo Numminen....20\n",
      ">: D-Peter Ahola.......13\n",
      ">: \n",
      ">Well well, they don't like our defenders (mainly Lumme and Numminen)...\n",
      "\n",
      "About 25 is correct for Numminen and Lumme.\n",
      "\n",
      "\n",
      ">: R-Teemu Selanne.....27\n",
      ">: \n",
      ">Compared to Kurri, Selanne's points are too high, lets make it 25 or 26.\n",
      "\n",
      "No, Kurri's points are too low. 27 for Kurri and 28 for Sel{nne.\n",
      "\n",
      ">: well in the Canada Cup and World Championships largely due to the efforts of\n",
      ">: Markus Ketterer (the goalie), 3-4 or the players listed above and luck. There's\n",
      ">: presumably a lot of decent players in Finland that wouldn't be superstars at\n",
      ">: the highest level but still valuable role players, however. My guess would be\n",
      ">: that the Finnish Canada Cup team would be a .500 team in the NHL.\n",
      "\n",
      ">Wow, now, it looks like you don't like our players? What about guys like:\n",
      ">Nieminen, Jutila, Riihijarvi, Varvio, Laukkanen, Makela, Keskinen and (even\n",
      ">if he is aging) Ruotsalainen? The main difference between finnish and North-\n",
      ">American players is, that our players tend to be better in the larger rink.\n",
      ">The Canadian defenders are usually slower that defenders in Europe. \n",
      ">And I think that there was more in our success than Ketterer and luck (though\n",
      ">they helped). I think that the main reason was, that the team worked well\n",
      ">together.\n",
      "\n",
      "\n",
      "That's true. Game is so different here in Europe compared to NHL. North-ame-\n",
      "ricans are better in small rinks and europeans in large rinks. An average\n",
      "european player from Sweden, Finland, Russian or Tsech/Slovakia is a better \n",
      "skater and  puckhandler than his NHL colleague. Especially defenders in NHL\n",
      "are mainly slow and clumsy. Sel{nne has also said that in the Finnish Sm-league\n",
      "game is more based on skill than in NHL. In Finland he couldn't get so many \n",
      "breakaways because defenders here are an average much better skaters than in\n",
      "NHL. Also Alpo Suhonen said that in NHL Sel{nne's speed accentuates because\n",
      "of clumsy defensemen.\n",
      "\n",
      "I have to admit that the best players come from Canada, but those regulars\n",
      "aren't as skilful as regulars in the best european leagues. Also top europeans\n",
      "are in the same level as the best north-americans.(except Lemieux is in the\n",
      "class of his own). \n",
      "\n",
      "Tommi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2303"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.26052974381241856\n",
      "1 0.25749023013460703\n",
      "2 0.23708206686930092\n",
      "3 0.24489795918367346\n"
     ]
    }
   ],
   "source": [
    "#是否存在样本不平衡问题：否\n",
    "for i in [0,1,2,3]:\n",
    "    print(i,(train.target == i).sum()/len(train.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （三）使用TF-IDF降文本数据编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = train.data\n",
    "Xtest = test.data\n",
    "Ytrain = train.target\n",
    "Ytest = test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDF().fit(Xtrain) #用训练集拟合\n",
    "Xtrain_ = tfidf.transform(Xtrain)\n",
    "Xtest_ = tfidf.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2303x40725 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 430306 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_ #稀疏矩阵，2303行，40725个特征（不重复的单词）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00000</th>\n",
       "      <th>000000</th>\n",
       "      <th>000021</th>\n",
       "      <th>000062david42</th>\n",
       "      <th>000152</th>\n",
       "      <th>000246</th>\n",
       "      <th>000256</th>\n",
       "      <th>...</th>\n",
       "      <th>zwrm</th>\n",
       "      <th>zx</th>\n",
       "      <th>zx6wre</th>\n",
       "      <th>zxp</th>\n",
       "      <th>zxqi</th>\n",
       "      <th>zy</th>\n",
       "      <th>zyg</th>\n",
       "      <th>zz</th>\n",
       "      <th>zz_g9q3</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40725 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00       000  0000  00000  000000  000021  000062david42  000152  000246  \\\n",
       "0  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "1  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "2  0.0  0.058046   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "3  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "4  0.0  0.000000   0.0    0.0     0.0     0.0            0.0     0.0     0.0   \n",
       "\n",
       "   000256  ...  zwrm   zx  zx6wre  zxp  zxqi   zy  zyg   zz  zz_g9q3  zzzzzz  \n",
       "0     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "1     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "2     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "3     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "4     0.0  ...   0.0  0.0     0.0  0.0   0.0  0.0  0.0  0.0      0.0     0.0  \n",
       "\n",
       "[5 rows x 40725 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosee = pd.DataFrame(Xtrain_.toarray(),columns=tfidf.get_feature_names())\n",
    "tosee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2303, 40725)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tosee.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （四）在贝叶斯上分别建模，查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"Multinomial\",\"Complement\",\"Bournulli\"]\n",
    "#注意高斯朴素贝叶斯不接受稀疏矩阵\n",
    "models = [MultinomialNB(),ComplementNB(),BernoulliNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial\n",
      "\tBrier under rec.sport.hockey:0.018\n",
      "\tBrier under sci.space:0.033\n",
      "\tBrier under talk.politics.guns:0.030\n",
      "\tBrier under talk.politics.mideast:0.026\n",
      "\tAverage Brier:0.027\n",
      "\tAccuracy:0.975\n",
      "\n",
      "\n",
      "Complement\n",
      "\tBrier under rec.sport.hockey:0.023\n",
      "\tBrier under sci.space:0.039\n",
      "\tBrier under talk.politics.guns:0.039\n",
      "\tBrier under talk.politics.mideast:0.033\n",
      "\tAverage Brier:0.033\n",
      "\tAccuracy:0.986\n",
      "\n",
      "\n",
      "Bournulli\n",
      "\tBrier under rec.sport.hockey:0.068\n",
      "\tBrier under sci.space:0.025\n",
      "\tBrier under talk.politics.guns:0.045\n",
      "\tBrier under talk.politics.mideast:0.053\n",
      "\tAverage Brier:0.048\n",
      "\tAccuracy:0.902\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,clf in zip(name,models):\n",
    "    clf.fit(Xtrain_,Ytrain)\n",
    "    y_pred = clf.predict(Xtest_)\n",
    "    proba = clf.predict_proba(Xtest_)\n",
    "    score = clf.score(Xtest_,Ytest)\n",
    "    print(name)\n",
    "    \n",
    "    #4个不同的标签取值下的布里尔分数\n",
    "    Bscore = []\n",
    "    for i in range(len(np.unique(Ytrain))):\n",
    "        bs = BS(pd.get_dummies(Ytest).iloc[:,i],proba[:,i],pos_label=1)\n",
    "        Bscore.append(bs)\n",
    "        print(\"\\tBrier under {}:{:.3f}\".format(train.target_names[i],bs))\n",
    "    \n",
    "    print(\"\\tAverage Brier:{:.3f}\".format(np.mean(Bscore)))\n",
    "    print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果上来看，两种贝叶斯的效果都很不错。虽然补集贝叶斯的布里尔分数更高，但它的精确度更高。可以使用概率校准来试试看能否让模型进一步突破："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial\n",
      "\tBrier under rec.sport.hockey:0.018\n",
      "\tBrier under sci.space:0.033\n",
      "\tBrier under talk.politics.guns:0.030\n",
      "\tBrier under talk.politics.mideast:0.026\n",
      "Multinomial + Isotonic\n",
      "\tBrier under rec.sport.hockey:0.006\n",
      "\tBrier under sci.space:0.012\n",
      "\tBrier under talk.politics.guns:0.013\n",
      "\tBrier under talk.politics.mideast:0.009\n",
      "Multinomial + Sigmoid\n",
      "\tBrier under rec.sport.hockey:0.006\n",
      "\tBrier under sci.space:0.012\n",
      "\tBrier under talk.politics.guns:0.013\n",
      "\tBrier under talk.politics.mideast:0.009\n",
      "Complement\n",
      "\tBrier under rec.sport.hockey:0.023\n",
      "\tBrier under sci.space:0.039\n",
      "\tBrier under talk.politics.guns:0.039\n",
      "\tBrier under talk.politics.mideast:0.033\n",
      "Complement + Isotonic\n",
      "\tBrier under rec.sport.hockey:0.004\n",
      "\tBrier under sci.space:0.007\n",
      "\tBrier under talk.politics.guns:0.009\n",
      "\tBrier under talk.politics.mideast:0.006\n",
      "Complement + Sigmoid\n",
      "\tBrier under rec.sport.hockey:0.004\n",
      "\tBrier under sci.space:0.009\n",
      "\tBrier under talk.politics.guns:0.010\n",
      "\tBrier under talk.politics.mideast:0.007\n",
      "Bernoulli\n",
      "\tBrier under rec.sport.hockey:0.068\n",
      "\tBrier under sci.space:0.025\n",
      "\tBrier under talk.politics.guns:0.045\n",
      "\tBrier under talk.politics.mideast:0.053\n",
      "Bernoulli + Isotonic\n",
      "\tBrier under rec.sport.hockey:0.020\n",
      "\tBrier under sci.space:0.017\n",
      "\tBrier under talk.politics.guns:0.032\n",
      "\tBrier under talk.politics.mideast:0.035\n",
      "Bernoulli + Sigmoid\n",
      "\tBrier under rec.sport.hockey:0.066\n",
      "\tBrier under sci.space:0.030\n",
      "\tBrier under talk.politics.guns:0.056\n",
      "\tBrier under talk.politics.mideast:0.059\n",
      "\tAverage Brier:0.053\n",
      "\tAccuracy:0.879\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = [\"Multinomial\"\n",
    "        ,\"Multinomial + Isotonic\"\n",
    "        ,\"Multinomial + Sigmoid\"\n",
    "        ,\"Complement\"\n",
    "        ,\"Complement + Isotonic\"\n",
    "        ,\"Complement + Sigmoid\"\n",
    "        ,\"Bernoulli\"\n",
    "        ,\"Bernoulli + Isotonic\"\n",
    "        ,\"Bernoulli + Sigmoid\"]\n",
    "\n",
    "models = [MultinomialNB()\n",
    "         ,CalibratedClassifierCV(MultinomialNB(), cv=2, method='isotonic')\n",
    "         ,CalibratedClassifierCV(MultinomialNB(), cv=2, method='sigmoid')\n",
    "         ,ComplementNB()\n",
    "         ,CalibratedClassifierCV(ComplementNB(), cv=2, method='isotonic')\n",
    "         ,CalibratedClassifierCV(ComplementNB(), cv=2, method='sigmoid')\n",
    "         ,BernoulliNB()\n",
    "         ,CalibratedClassifierCV(BernoulliNB(), cv=2, method='isotonic')\n",
    "         ,CalibratedClassifierCV(BernoulliNB(), cv=2, method='sigmoid')\n",
    "         ]\n",
    "\n",
    "for name,clf in zip(name,models):\n",
    "    clf.fit(Xtrain_,Ytrain)\n",
    "    y_pred = clf.predict(Xtest_)\n",
    "    proba = clf.predict_proba(Xtest_)\n",
    "    score = clf.score(Xtest_,Ytest)\n",
    "    print(name)\n",
    "    Bscore = []\n",
    "    for i in range(len(np.unique(Ytrain))):\n",
    "        bs = BS(pd.get_dummies(Ytest).iloc[:,i],proba[:,i],pos_label=1)\n",
    "        Bscore.append(bs)\n",
    "        print(\"\\tBrier under {}:{:.3f}\".format(train.target_names[i],bs))\n",
    "print(\"\\tAverage Brier:{:.3f}\".format(np.mean(Bscore)))\n",
    "print(\"\\tAccuracy:{:.3f}\".format(score))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以观察到，多项式分布下无论如何调整，算法的效果都不如补集朴素贝叶斯好。因此在分类的时候，应该选择**补集朴素贝叶斯**。对于补集朴素贝叶斯来说，使用Sigmoid进行概率校准的模型综合最优秀：准确率最高，对数损失和布里尔分数都在0.1以下，可以说是非常理想的模型了。<br>\n",
    "对于机器学习而言，朴素贝叶斯也许不是最常用的分类算法，但作为概率预测算法中唯——个真正**依赖概率**来进行计算，并且简单快捷的算法，朴素贝叶斯还是常常被人们提起。并且，朴素贝叶斯在文本分类上的效果的确非常优秀。由此可见，只要能够提供足够的数据，合理利用高维数据进行训练，朴素贝叶斯就可以提供意想不到的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
